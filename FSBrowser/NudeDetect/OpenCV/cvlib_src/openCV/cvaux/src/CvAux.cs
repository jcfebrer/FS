////*******************************************************************
//// File name: $ CvAux.cs $
//// Author:		$ Heiko Kieﬂling, (c) iib-chemnitz.de $
//// Email:			hki@hrz.tu-chemnitz.de
//// 
//// License:		There is no explicit license attached. The code is
////						provided 'as is'. Feel free to use the code how you like 
////						but without any warranty.
////						If you include the code in your own projects and/or
////						redistribute pls. include this header.
////
//// History:		Rev. 1.0 (beta), hki - initial revision
//// ToDo:			Documentation
////*******************************************************************
//// Code generated by hand
////*******************************************************************


//using System;
//using System.Collections.Generic;
//using System.Text;

//namespace openCV
//{
//  public partial class cvlib
//  {
//    CVAPI(CvSeq*) cvSegmentImage( const CvArr* srcarr, CvArr* dstarr,
//                                    double canny_threshold,
//                                    double ffill_threshold,
//                                    CvMemStorage* storage );

///* Calculates covariation matrix of a set of arrays */
//CVAPI(void)  cvCalcCovarMatrixEx( int nObjects, void* input, int ioFlags,
//                                  int ioBufSize, uchar* buffer, void* userData,
//                                  IplImage* avg, float* covarMatrix );

///* Calculates eigen values and vectors of covariation matrix of a set of
//   arrays */
//CVAPI(void)  cvCalcEigenObjects( int nObjects, void* input, void* output,
//                                 int ioFlags, int ioBufSize, void* userData,
//                                 CvTermCriteria* calcLimit, IplImage* avg,
//                                 float* eigVals );

///* Calculates dot product (obj - avg) * eigObj (i.e. projects image to eigen vector) */
//CVAPI(double)  cvCalcDecompCoeff( IplImage* obj, IplImage* eigObj, IplImage* avg );

///* Projects image to eigen space (finds all decomposion coefficients */
//CVAPI(void)  cvEigenDecomposite( IplImage* obj, int nEigObjs, void* eigInput,
//                                 int ioFlags, void* userData, IplImage* avg,
//                                 float* coeffs );

///* Projects original objects used to calculate eigen space basis to that space */
//CVAPI(void)  cvEigenProjection( void* eigInput, int nEigObjs, int ioFlags,
//                                void* userData, float* coeffs, IplImage* avg,
//                                IplImage* proj );


///*********************************** Embedded HMMs *************************************/

///* Creates 2D HMM */
//CVAPI(CvEHMM*)  cvCreate2DHMM( int* stateNumber, int* numMix, int obsSize );

///* Releases HMM */
//CVAPI(void)  cvRelease2DHMM( CvEHMM** hmm );

///* Creates storage for observation vectors */
//CVAPI(CvImgObsInfo*)  cvCreateObsInfo( CvSize numObs, int obsSize );

///* Releases storage for observation vectors */
//CVAPI(void)  cvReleaseObsInfo( CvImgObsInfo** obs_info );


///* The function takes an image on input and and returns the sequnce of observations
//   to be used with an embedded HMM; Each observation is top-left block of DCT
//   coefficient matrix */
//CVAPI(void)  cvImgToObs_DCT( const CvArr* arr, float* obs, CvSize dctSize,
//                             CvSize obsSize, CvSize delta );


///* Uniformly segments all observation vectors extracted from image */
//CVAPI(void)  cvUniformImgSegm( CvImgObsInfo* obs_info, CvEHMM* ehmm );

///* Does mixture segmentation of the states of embedded HMM */
//CVAPI(void)  cvInitMixSegm( CvImgObsInfo** obs_info_array,
//                            int num_img, CvEHMM* hmm );

///* Function calculates means, variances, weights of every Gaussian mixture
//   of every low-level state of embedded HMM */
//CVAPI(void)  cvEstimateHMMStateParams( CvImgObsInfo** obs_info_array,
//                                       int num_img, CvEHMM* hmm );

///* Function computes transition probability matrices of embedded HMM
//   given observations segmentation */
//CVAPI(void)  cvEstimateTransProb( CvImgObsInfo** obs_info_array,
//                                  int num_img, CvEHMM* hmm );

///* Function computes probabilities of appearing observations at any state
//   (i.e. computes P(obs|state) for every pair(obs,state)) */
//CVAPI(void)  cvEstimateObsProb( CvImgObsInfo* obs_info,
//                                CvEHMM* hmm );

///* Runs Viterbi algorithm for embedded HMM */
//CVAPI(float)  cvEViterbi( CvImgObsInfo* obs_info, CvEHMM* hmm );


///* Function clusters observation vectors from several images
//   given observations segmentation.
//   Euclidean distance used for clustering vectors.
//   Centers of clusters are given means of every mixture */
//CVAPI(void)  cvMixSegmL2( CvImgObsInfo** obs_info_array,
//                          int num_img, CvEHMM* hmm );

///****************************************************************************************\
//*               A few functions from old stereo gesture recognition demosions            *
//\****************************************************************************************/

///* Creates hand mask image given several points on the hand */
//CVAPI(void)  cvCreateHandMask( CvSeq* hand_points,
//                                   IplImage *img_mask, CvRect *roi);

///* Finds hand region in range image data */
//CVAPI(void)  cvFindHandRegion (CvPoint3D32f* points, int count,
//                                CvSeq* indexs,
//                                float* line, CvSize2D32f size, int flag,
//                                CvPoint3D32f* center,
//                                CvMemStorage* storage, CvSeq **numbers);

///* Finds hand region in range image data (advanced version) */
//CVAPI(void)  cvFindHandRegionA( CvPoint3D32f* points, int count,
//                                CvSeq* indexs,
//                                float* line, CvSize2D32f size, int jc,
//                                CvPoint3D32f* center,
//                                CvMemStorage* storage, CvSeq **numbers);

///****************************************************************************************\
//*                           Additional operations on Subdivisions                        *
//\****************************************************************************************/

//// paints voronoi diagram: just demo function
//CVAPI(void)  icvDrawMosaic( CvSubdiv2D* subdiv, IplImage* src, IplImage* dst );

//// checks planar subdivision for correctness. It is not an absolute check,
//// but it verifies some relations between quad-edges
//CVAPI(int)   icvSubdiv2DCheck( CvSubdiv2D* subdiv );


///****************************************************************************************\
//*                           More operations on sequences                                 *
//\****************************************************************************************/

///*****************************************************************************************/
///*****************************************************************************************/
///*******************************Stereo correspondence*************************************/
//CVAPI(void) 
//cvFindStereoCorrespondence( 
//                   const  CvArr* leftImage, const  CvArr* rightImage,
//                   int     mode,
//                   CvArr*  dispImage,
//                   int     maxDisparity,                                
//                   double  param1 CV_DEFAULT(CV_UNDEF_SC_PARAM), 
//                   double  param2 CV_DEFAULT(CV_UNDEF_SC_PARAM), 
//                   double  param3 CV_DEFAULT(CV_UNDEF_SC_PARAM), 
//                   double  param4 CV_DEFAULT(CV_UNDEF_SC_PARAM), 
//                   double  param5 CV_DEFAULT(CV_UNDEF_SC_PARAM) );

///*****************************************************************************************/
///************ Epiline functions *******************/

//CVAPI(int) icvConvertWarpCoordinates(double coeffs[3][3],
//                                CvPoint2D32f* cameraPoint,
//                                CvPoint2D32f* warpPoint,
//                                int direction);

//CVAPI(int) icvGetSymPoint3D(  CvPoint3D64d pointCorner,
//                            CvPoint3D64d point1,
//                            CvPoint3D64d point2,
//                            CvPoint3D64d *pointSym2);

//CVAPI(void) icvGetPieceLength3D(CvPoint3D64d point1,CvPoint3D64d point2,double* dist);

//CVAPI(int) icvCompute3DPoint(    double alpha,double betta,
//                            CvStereoLineCoeff* coeffs,
//                            CvPoint3D64d* point);

//CVAPI(int) icvCreateConvertMatrVect( CvMatr64d     rotMatr1,
//                                CvMatr64d     transVect1,
//                                CvMatr64d     rotMatr2,
//                                CvMatr64d     transVect2,
//                                CvMatr64d     convRotMatr,
//                                CvMatr64d     convTransVect);

//CVAPI(int) icvConvertPointSystem(CvPoint3D64d  M2,
//                            CvPoint3D64d* M1,
//                            CvMatr64d     rotMatr,
//                            CvMatr64d     transVect
//                            );

//CVAPI(int) icvComputeCoeffForStereo(  CvStereoCamera* stereoCamera);

//CVAPI(int) icvGetCrossPieceVector(CvPoint2D32f p1_start,CvPoint2D32f p1_end,CvPoint2D32f v2_start,CvPoint2D32f v2_end,CvPoint2D32f *cross);
//CVAPI(int) icvGetCrossLineDirect(CvPoint2D32f p1,CvPoint2D32f p2,float a,float b,float c,CvPoint2D32f* cross);
//CVAPI(float) icvDefinePointPosition(CvPoint2D32f point1,CvPoint2D32f point2,CvPoint2D32f point);
//CVAPI(int) icvStereoCalibration( int numImages,
//                            int* nums,
//                            CvSize imageSize,
//                            CvPoint2D32f* imagePoints1,
//                            CvPoint2D32f* imagePoints2,
//                            CvPoint3D32f* objectPoints,
//                            CvStereoCamera* stereoparams
//                           );


//CVAPI(int) icvComputeRestStereoParams(CvStereoCamera *stereoparams);

//CVAPI(void) cvComputePerspectiveMap( const double coeffs[3][3], CvArr* rectMapX, CvArr* rectMapY );

//CVAPI(int) icvComCoeffForLine(   CvPoint2D64d point1,
//                            CvPoint2D64d point2,
//                            CvPoint2D64d point3,
//                            CvPoint2D64d point4,
//                            CvMatr64d    camMatr1,
//                            CvMatr64d    rotMatr1,
//                            CvMatr64d    transVect1,
//                            CvMatr64d    camMatr2,
//                            CvMatr64d    rotMatr2,
//                            CvMatr64d    transVect2,
//                            CvStereoLineCoeff*    coeffs,
//                            int* needSwapCameras);

//CVAPI(int) icvGetDirectionForPoint(  CvPoint2D64d point,
//                                CvMatr64d camMatr,
//                                CvPoint3D64d* direct);

//CVAPI(int) icvGetCrossLines(CvPoint3D64d point11,CvPoint3D64d point12,
//                       CvPoint3D64d point21,CvPoint3D64d point22,
//                       CvPoint3D64d* midPoint);

//CVAPI(int) icvComputeStereoLineCoeffs(   CvPoint3D64d pointA,
//                                    CvPoint3D64d pointB,
//                                    CvPoint3D64d pointCam1,
//                                    double gamma,
//                                    CvStereoLineCoeff*    coeffs);

//CVAPI(int) icvGetAngleLine( CvPoint2D64d startPoint, CvSize imageSize,CvPoint2D64d *point1,CvPoint2D64d *point2);

//CVAPI(void) icvGetCoefForPiece(   CvPoint2D64d p_start,CvPoint2D64d p_end,
//                        double *a,double *b,double *c,
//                        int* result);

//CVAPI(void) icvComputeeInfiniteProject1(CvMatr64d    rotMatr,
//                                     CvMatr64d    camMatr1,
//                                     CvMatr64d    camMatr2,
//                                     CvPoint2D32f point1,
//                                     CvPoint2D32f *point2);

//CVAPI(void) icvComputeeInfiniteProject2(CvMatr64d    rotMatr,
//                                     CvMatr64d    camMatr1,
//                                     CvMatr64d    camMatr2,
//                                     CvPoint2D32f* point1,
//                                     CvPoint2D32f point2);

//CVAPI(void) icvGetCrossDirectDirect(  CvVect64d direct1,CvVect64d direct2,
//                            CvPoint2D64d *cross,int* result);

//CVAPI(void) icvGetCrossPieceDirect(   CvPoint2D64d p_start,CvPoint2D64d p_end,
//                            double a,double b,double c,
//                            CvPoint2D64d *cross,int* result);

//CVAPI(void) icvGetCrossPiecePiece( CvPoint2D64d p1_start,CvPoint2D64d p1_end,
//                            CvPoint2D64d p2_start,CvPoint2D64d p2_end,
//                            CvPoint2D64d* cross,
//                            int* result);
                            
//CVAPI(void) icvGetPieceLength(CvPoint2D64d point1,CvPoint2D64d point2,double* dist);

//CVAPI(void) icvGetCrossRectDirect(    CvSize imageSize,
//                            double a,double b,double c,
//                            CvPoint2D64d *start,CvPoint2D64d *end,
//                            int* result);

//CVAPI(void) icvProjectPointToImage(   CvPoint3D64d point,
//                            CvMatr64d camMatr,CvMatr64d rotMatr,CvVect64d transVect,
//                            CvPoint2D64d* projPoint);

//CVAPI(void) icvGetQuadsTransform( CvSize        imageSize,
//                        CvMatr64d     camMatr1,
//                        CvMatr64d     rotMatr1,
//                        CvVect64d     transVect1,
//                        CvMatr64d     camMatr2,
//                        CvMatr64d     rotMatr2,
//                        CvVect64d     transVect2,
//                        CvSize*       warpSize,
//                        double quad1[4][2],
//                        double quad2[4][2],
//                        CvMatr64d     fundMatr,
//                        CvPoint3D64d* epipole1,
//                        CvPoint3D64d* epipole2
//                        );

//CVAPI(void) icvGetQuadsTransformStruct(  CvStereoCamera* stereoCamera);

//CVAPI(void) icvComputeStereoParamsForCameras(CvStereoCamera* stereoCamera);

//CVAPI(void) icvGetCutPiece(   CvVect64d areaLineCoef1,CvVect64d areaLineCoef2,
//                    CvPoint2D64d epipole,
//                    CvSize imageSize,
//                    CvPoint2D64d* point11,CvPoint2D64d* point12,
//                    CvPoint2D64d* point21,CvPoint2D64d* point22,
//                    int* result);

//CVAPI(void) icvGetMiddleAnglePoint(   CvPoint2D64d basePoint,
//                            CvPoint2D64d point1,CvPoint2D64d point2,
//                            CvPoint2D64d* midPoint);

//CVAPI(void) icvGetNormalDirect(CvVect64d direct,CvPoint2D64d point,CvVect64d normDirect);

//CVAPI(double) icvGetVect(CvPoint2D64d basePoint,CvPoint2D64d point1,CvPoint2D64d point2);

//CVAPI(void) icvProjectPointToDirect(  CvPoint2D64d point,CvVect64d lineCoeff,
//                            CvPoint2D64d* projectPoint);

//CVAPI(void) icvGetDistanceFromPointToDirect( CvPoint2D64d point,CvVect64d lineCoef,double*dist);

//CVAPI(IplImage*) icvCreateIsometricImage( IplImage* src, IplImage* dst,
//                              int desired_depth, int desired_num_channels );

//CVAPI(void) cvDeInterlace( const CvArr* frame, CvArr* fieldEven, CvArr* fieldOdd );


///****************************************************************************************\
//*                                   Contour Morphing                                     *
//\****************************************************************************************/

///* finds correspondence between two contours */
//CvSeq* cvCalcContoursCorrespondence( const CvSeq* contour1,
//                                     const CvSeq* contour2, 
//                                     CvMemStorage* storage);

///* morphs contours using the pre-calculated correspondence:
//   alpha=0 ~ contour1, alpha=1 ~ contour2 */
//CvSeq* cvMorphContours( const CvSeq* contour1, const CvSeq* contour2,
//                        CvSeq* corr, double alpha,
//                        CvMemStorage* storage );

///****************************************************************************************\
//*                                    Texture Descriptors                                 *
//\****************************************************************************************/


//CVAPI(CvGLCM*) cvCreateGLCM( const IplImage* srcImage,
//                                int stepMagnitude,
//                                const int* stepDirections CV_DEFAULT(0),
//                                int numStepDirections CV_DEFAULT(0),
//                                int optimizationType CV_DEFAULT(CV_GLCM_OPTIMIZATION_NONE));

//CVAPI(void) cvReleaseGLCM( CvGLCM** GLCM, int flag CV_DEFAULT(CV_GLCM_ALL));

//CVAPI(void) cvCreateGLCMDescriptors( CvGLCM* destGLCM,
//                                        int descriptorOptimizationType
//                                        CV_DEFAULT(CV_GLCMDESC_OPTIMIZATION_ALLOWDOUBLENEST));

//CVAPI(double) cvGetGLCMDescriptor( CvGLCM* GLCM, int step, int descriptor );

//CVAPI(void) cvGetGLCMDescriptorStatistics( CvGLCM* GLCM, int descriptor,
//                                              double* average, double* standardDeviation );

//CVAPI(IplImage*) cvCreateGLCMImage( CvGLCM* GLCM, int step );

///****************************************************************************************\
//*                                  Face eyes&mouth tracking                              *
//\****************************************************************************************/

//CVAPI(CvFaceTracker*) cvInitFaceTracker(CvFaceTracker* pFaceTracking, const IplImage* imgGray,
//                                                CvRect* pRects, int nRects);
//CVAPI(int) cvTrackFace( CvFaceTracker* pFaceTracker, IplImage* imgGray,
//                              CvRect* pRects, int nRects,
//                              CvPoint* ptRotate, double* dbAngleRotate);
//CVAPI(void) cvReleaseFaceTracker(CvFaceTracker** ppFaceTracker);

//CvSeq * cvFindFace(IplImage * Image,CvMemStorage* storage);
//CvSeq * cvPostBoostingFindFace(IplImage * Image,CvMemStorage* storage);


///****************************************************************************************\
//*                                         3D Tracker                                     *
//\****************************************************************************************/

//CVAPI(CvBool) cv3dTrackerCalibrateCameras(int num_cameras,
//                     const Cv3dTrackerCameraIntrinsics camera_intrinsics[], /* size is num_cameras */
//                     CvSize etalon_size,
//                     float square_size,
//                     IplImage *samples[],                                   /* size is num_cameras */
//                     Cv3dTrackerCameraInfo camera_info[]);                  /* size is num_cameras */

//CVAPI(int)  cv3dTrackerLocateObjects(int num_cameras, int num_objects,
//                   const Cv3dTrackerCameraInfo camera_info[],        /* size is num_cameras */
//                   const Cv3dTracker2dTrackedObject tracking_info[], /* size is num_objects*num_cameras */
//                   Cv3dTrackerTrackedObject tracked_objects[]);      /* size is num_objects */

///****************************************************************************************
// tracking_info is a rectangular array; one row per camera, num_objects elements per row.
// The id field of any unused slots must be -1. Ids need not be ordered or consecutive. On
// completion, the return value is the number of objects located; i.e., the number of objects
// visible by more than one camera. The id field of any unused slots in tracked objects is
// set to -1.
//****************************************************************************************/

///****************************************************************************************\
//*                           Skeletons and Linear-Contour Models                          *
//\****************************************************************************************/

///* Computes Voronoi Diagram for given polygons with holes */
//CVAPI(int)  cvVoronoiDiagramFromContour(CvSeq* ContourSeq,
//                                           CvVoronoiDiagram2D** VoronoiDiagram,
//                                           CvMemStorage* VoronoiStorage,
//                                           CvLeeParameters contour_type CV_DEFAULT(CV_LEE_INT),
//                                           int contour_orientation CV_DEFAULT(-1),
//                                           int attempt_number CV_DEFAULT(10));

///* Computes Voronoi Diagram for domains in given image */
//CVAPI(int)  cvVoronoiDiagramFromImage(IplImage* pImage,
//                                         CvSeq** ContourSeq,
//                                         CvVoronoiDiagram2D** VoronoiDiagram,
//                                         CvMemStorage* VoronoiStorage,
//                                         CvLeeParameters regularization_method CV_DEFAULT(CV_LEE_NON),
//                                         float approx_precision CV_DEFAULT(CV_LEE_AUTO));

///* Deallocates the storage */
//CVAPI(void) cvReleaseVoronoiStorage(CvVoronoiDiagram2D* VoronoiDiagram,
//                                          CvMemStorage** pVoronoiStorage);

///*********************** Linear-Contour Model ****************************/

///* Computes hybrid model from Voronoi Diagram */
//CVAPI(CvGraph*) cvLinearContorModelFromVoronoiDiagram(CvVoronoiDiagram2D* VoronoiDiagram,
//                                                         float maxWidth);

///* Releases hybrid model storage */
//CVAPI(int) cvReleaseLinearContorModelStorage(CvGraph** Graph);


///* two stereo-related functions */

//CVAPI(void) cvInitPerspectiveTransform( CvSize size, const CvPoint2D32f vertex[4], double matrix[3][3],
//                                              CvArr* rectMap );
///*************************** View Morphing Functions ************************/

///* The order of the function corresponds to the order they should appear in
//   the view morphing pipeline */ 

///* Finds ending points of scanlines on left and right images of stereo-pair */
//CVAPI(void)  cvMakeScanlines( const CvMatrix3* matrix, CvSize  img_size,
//                              int*  scanlines1, int*  scanlines2,
//                              int*  lengths1, int*  lengths2,
//                              int*  line_count );

///* Grab pixel values from scanlines and stores them sequentially
//   (some sort of perspective image transform) */
//CVAPI(void)  cvPreWarpImage( int       line_count,
//                             IplImage* img,
//                             uchar*    dst,
//                             int*      dst_nums,
//                             int*      scanlines);

///* Approximate each grabbed scanline by a sequence of runs
//   (lossy run-length compression) */
//CVAPI(void)  cvFindRuns( int    line_count,
//                         uchar* prewarp1,
//                         uchar* prewarp2,
//                         int*   line_lengths1,
//                         int*   line_lengths2,
//                         int*   runs1,
//                         int*   runs2,
//                         int*   num_runs1,
//                         int*   num_runs2);

///* Compares two sets of compressed scanlines */
//CVAPI(void)  cvDynamicCorrespondMulti( int  line_count,
//                                       int* first,
//                                       int* first_runs,
//                                       int* second,
//                                       int* second_runs,
//                                       int* first_corr,
//                                       int* second_corr);

///* Finds scanline ending coordinates for some intermediate "virtual" camera position */
//CVAPI(void)  cvMakeAlphaScanlines( int*  scanlines1,
//                                   int*  scanlines2,
//                                   int*  scanlinesA,
//                                   int*  lengths,
//                                   int   line_count,
//                                   float alpha);

///* Blends data of the left and right image scanlines to get
//   pixel values of "virtual" image scanlines */
//CVAPI(void)  cvMorphEpilinesMulti( int    line_count,
//                                   uchar* first_pix,
//                                   int*   first_num,
//                                   uchar* second_pix,
//                                   int*   second_num,
//                                   uchar* dst_pix,
//                                   int*   dst_num,
//                                   float  alpha,
//                                   int*   first,
//                                   int*   first_runs,
//                                   int*   second,
//                                   int*   second_runs,
//                                   int*   first_corr,
//                                   int*   second_corr);

///* Does reverse warping of the morphing result to make
//   it fill the destination image rectangle */
//CVAPI(void)  cvPostWarpImage( int       line_count,
//                              uchar*    src,
//                              int*      src_nums,
//                              IplImage* img,
//                              int*      scanlines);

///* Deletes Moire (missed pixels that appear due to discretization) */
//CVAPI(void)  cvDeleteMoire( IplImage*  img );


///****************************************************************************************\
//*                           Background/foreground segmentation                           *
//\****************************************************************************************/

//// Performs FG post-processing using segmentation
//// (all pixels of a region will be classified as foreground if majority of pixels of the region are FG).
//// parameters:
////      segments - pointer to result of segmentation (for example MeanShiftSegmentation)
////      bg_model - pointer to CvBGStatModel structure
//CVAPI(void) cvRefineForegroundMaskBySegm( CvSeq* segments, CvBGStatModel*  bg_model );

///* Common use change detection function */
//CVAPI(int)  cvChangeDetection( IplImage*  prev_frame,
//                               IplImage*  curr_frame,
//                               IplImage*  change_mask );


///* Creates FGD model */
//CVAPI(CvBGStatModel*) cvCreateFGDStatModel( IplImage* first_frame,
//                    CvFGDStatModelParams* parameters CV_DEFAULT(NULL));

///* 
//   Interface of Gaussian mixture algorithm
//   (P. KadewTraKuPong and R. Bowden,
//   "An improved adaptive background mixture model for real-time tracking with shadow detection"
//   in Proc. 2nd European Workshp on Advanced Video-Based Surveillance Systems, 2001.")
//*/


///* Creates Gaussian mixture background model */
//CVAPI(CvBGStatModel*) cvCreateGaussianBGModel( IplImage* first_frame,
//                CvGaussBGStatModelParams* parameters CV_DEFAULT(NULL));

///****************************************************************************************\
//*                                   Calibration engine                                   *
//\****************************************************************************************/
//}

//// public class CV_EXPORTS CvCalibFilter
//// {
//// public:
////     /* Constructor & destructor */
////     CvCalibFilter();
////     virtual ~CvCalibFilter();

////     /* Sets etalon type - one for all cameras.
////        etalonParams is used in case of pre-defined etalons (such as chessboard).
////        Number of elements in etalonParams is determined by etalonType.
////        E.g., if etalon type is CV_ETALON_TYPE_CHESSBOARD then:
////          etalonParams[0] is number of squares per one side of etalon
////          etalonParams[1] is number of squares per another side of etalon
////          etalonParams[2] is linear size of squares in the board in arbitrary units.
////        pointCount & points are used in case of
////        CV_CALIB_ETALON_USER (user-defined) etalon. */
////     virtual bool
////         SetEtalon( CvCalibEtalonType etalonType, double* etalonParams,
////                    int pointCount = 0, CvPoint2D32f* points = 0 );

////     /* Retrieves etalon parameters/or and points */
////     virtual CvCalibEtalonType
////         GetEtalon( int* paramCount = 0, const double** etalonParams = 0,
////                    int* pointCount = 0, const CvPoint2D32f** etalonPoints = 0 ) const;

////     /* Sets number of cameras calibrated simultaneously. It is equal to 1 initially */
////     virtual void SetCameraCount( int cameraCount );

////     /* Retrieves number of cameras */
////     int GetCameraCount() const { return cameraCount; }

////     /* Starts cameras calibration */
////     virtual bool SetFrames( int totalFrames );
////     
////     /* Stops cameras calibration */
////     virtual void Stop( bool calibrate = false );

////     /* Retrieves number of cameras */
////     bool IsCalibrated() const { return isCalibrated; }

////     /* Feeds another serie of snapshots (one per each camera) to filter.
////        Etalon points on these images are found automatically.
////        If the function can't locate points, it returns false */
////     virtual bool FindEtalon( IplImage** imgs );

////     /* The same but takes matrices */
////     virtual bool FindEtalon( CvMat** imgs );

////     /* Lower-level function for feeding filter with already found etalon points.
////        Array of point arrays for each camera is passed. */
////     virtual bool Push( const CvPoint2D32f** points = 0 );

////     /* Returns total number of accepted frames and, optionally,
////        total number of frames to collect */
////     virtual int GetFrameCount( int* framesTotal = 0 ) const;

////     /* Retrieves camera parameters for specified camera.
////        If camera is not calibrated the function returns 0 */
////     virtual const CvCamera* GetCameraParams( int idx = 0 ) const;

////     virtual const CvStereoCamera* GetStereoParams() const;

////     /* Sets camera parameters for all cameras */
////     virtual bool SetCameraParams( CvCamera* params );

////     /* Saves all camera parameters to file */
////     virtual bool SaveCameraParams( const char* filename );
////     
////     /* Loads all camera parameters from file */
////     virtual bool LoadCameraParams( const char* filename );

////     /* Undistorts images using camera parameters. Some of src pointers can be NULL. */
////     virtual bool Undistort( IplImage** src, IplImage** dst );

////     /* Undistorts images using camera parameters. Some of src pointers can be NULL. */
////     virtual bool Undistort( CvMat** src, CvMat** dst );

////     /* Returns array of etalon points detected/partally detected
////        on the latest frame for idx-th camera */
////     virtual bool GetLatestPoints( int idx, CvPoint2D32f** pts,
////                                                   int* count, bool* found );

////     /* Draw the latest detected/partially detected etalon */
////     virtual void DrawPoints( IplImage** dst );

////     /* Draw the latest detected/partially detected etalon */
////     virtual void DrawPoints( CvMat** dst );

////     virtual bool Rectify( IplImage** srcarr, IplImage** dstarr );
////     virtual bool Rectify( CvMat** srcarr, CvMat** dstarr );

//// protected:

////     enum { MAX_CAMERAS = 3 };

////     /* etalon data */
////     CvCalibEtalonType  etalonType;
////     int     etalonParamCount;
////     double* etalonParams;
////     int     etalonPointCount;
////     CvPoint2D32f* etalonPoints;
////     CvSize  imgSize;
////     CvMat*  grayImg;
////     CvMat*  tempImg;
////     CvMemStorage* storage;

////     /* camera data */
////     int     cameraCount;
////     CvCamera cameraParams[MAX_CAMERAS];
////     CvStereoCamera stereo;
////     CvPoint2D32f* points[MAX_CAMERAS];
////     CvMat*  undistMap[MAX_CAMERAS][2];
////     CvMat*  undistImg;
////     int     latestCounts[MAX_CAMERAS];
////     CvPoint2D32f* latestPoints[MAX_CAMERAS];
////     CvMat*  rectMap[MAX_CAMERAS][2];

////     /* Added by Valery */
////     //CvStereoCamera stereoParams;

////     int     maxPoints;
////     int     framesTotal;
////     int     framesAccepted;
////     bool    isCalibrated;
//// };
